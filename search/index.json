[{"content":"Avant-propos Durant mon exp√©rience professionnelle pr√©c√©dente, j\u0026rsquo;ai exerc√© pendant 3 ans en tant qu\u0026rsquo;expert FinOps sur AWS. La fonction ayant √©t√© cr√©√©e avec moi, j\u0026rsquo;ai eu toute libert√© pour mettre en place le mod√®le que je souhaitais, avec sa m√©thodologie et ses outils. Avant d\u0026rsquo;oublier ce que je sais, je me suis dit qu\u0026rsquo;il serait peut-√™tre int√©ressant pour certains que je mette ce qui me reste en t√™te par √©crit, la litt√©rature en fran√ßais se faisant rare d\u0026rsquo;autant plus (si l\u0026rsquo;article pla√Æt, je ferai peut-√™tre une traduction en anglais).\nIl m\u0026rsquo;√©tait √©galement apparu, en discutant avec mes clients et d\u0026rsquo;autres experts, souvent issus d\u0026rsquo;entreprises de conseils, que ma vision pouvait diff√©rer de la leur et de ce qu\u0026rsquo;on trouve g√©n√©ralement dans les articles traitant du sujet. Je pense que cela vient du fait que je suis avant tout un OPS, g√©rant une production et les contraintes inh√©rentes. Mes recommandations et conseils ont toujours eu pour trame de fond une vraie exploitation des plateformes, de leurs performances et disponibilit√©s (travaillant pour un infog√©rant, si la plateforme tombait, c\u0026rsquo;√©taient mes coll√®gues et moi qui r√©glons les probl√®mes, possiblement en astreinte üòâ ).\nN\u0026rsquo;ayant de connaissances avanc√©es et n\u0026rsquo;ayant effectu√© des audits uniquement pour AWS, j\u0026rsquo;utiliserai dans cet article beaucoup de termes et conseils li√©s √† ce Cloud Provider, mais je pense que les √©l√©ments g√©n√©raux sont facilement transposables √† GCP et Azure.\nD√©finition La premi√®re des t√¢ches est bien entendu de d√©finir le terme de FinOps lui-m√™me. Il appara√Æt √©videmment qu\u0026rsquo;il est la contraction de deux termes (comme tous ces TrucOps √† la mode üòõ). Dans notre cas: Financial + Operations. Pas tr√®s parlant au demeurant, on s\u0026rsquo;attend plus √† de la comptabilit√© qu\u0026rsquo;√† de l\u0026rsquo;architecture Cloud.\nVoil√† donc ma d√©finition, avec des morceaux en gras et ce, √† dessein:\nLe FinOps analyse les architectures Cloud et leurs facturations associ√©es, afin de d√©gager des axes de limitations des co√ªts et/ou d‚Äô√©conomie, en assurant un niveau de risque faible et en prenant en compte les enjeux de l\u0026rsquo;entreprise.\nReprenons chacune des parties mises en exergue:\nanalyse les architectures: Le travail de FinOps est un travail d\u0026rsquo;ing√©nierie avant tout, si on se contente de pointer des lignes dans une feuille Excel pour trouver les services co√ªtant trop chers dans lesquels il faudrait tailler, cela ne marchera pas. facturations associ√©es: On enfonce une porte ouverte, mais il va de soit que pour cibler les axes d\u0026rsquo;am√©liorations, il faut savoir quels sont les services qui sont factur√©s et dans quelles mesures (r√©duire de 10% le co√ªt d\u0026rsquo;un service √† $100 reste moins int√©ressant avant que 2% d\u0026rsquo;un service √† $1000, par exemple). axes de limitations des co√ªts et/ou d‚Äô√©conomie: La distinction est tr√®s importante √† mon sens. On cherche souvent √† seulement diminuer les co√ªts, mais il faut aussi penser √† faire en sorte de contr√¥ler leurs √©volutions. J\u0026rsquo;ai souvent expliqu√© qu\u0026rsquo;une facture de Cloud Provider qui augmente, ce n\u0026rsquo;est pas forc√©ment anormal ou g√™nant, cela peut juste √™tre la cons√©quence logique de l\u0026rsquo;augmentation de l\u0026rsquo;activit√©. Vous avez plus de trafic, et donc plus de consommation mais surtout plus de chiffre d\u0026rsquo;affaires, ce qui est attendu. L√† o√π √ßa coince c\u0026rsquo;est quand la facture augmente alors que le CA baisse, ou bien que les deux croissent tous deux mais dans des ordres de grandeur tr√®s diff√©rents (co√ªts qui explosent par rapport aux revenus). un niveau de risque faible: Quand on met en place des actions FinOps, on pense souvent √† changer les types des Instances (VM), ou √† r√©-architecturer des portions de la plateforme. Il est alors tr√®s important de garder √† l\u0026rsquo;esprit que la plateforme doit assurer un service de m√™me qualit√© (voire plus), et il faut donc √™tre tr√®s prudent dans les choix et leurs mises en place. enjeux de l\u0026rsquo;entreprise: Une plateforme Cloud n\u0026rsquo;est apr√®s-tout qu\u0026rsquo;un outil, un moyen de d√©livrer un service, elle s\u0026rsquo;inscrit dans un cadre beaucoup plus vaste √† prendre en compte. Je pense par exemple √† la maturit√© de l\u0026rsquo;entreprise avec les technologies, ou bien aux contraintes l√©gales (PCI-DSS, HADS, etc). Trouver le bon dosage entre HA, Perfs et Co√ªts Fort de cette d√©finition, il convient d√©sormais d\u0026rsquo;expliciter ce qu\u0026rsquo;on vise en faisant du FinOps, ce qui va guider nos choix.\nIl s\u0026rsquo;agit de trouver le bon dosage entre 3 crit√®res:\nHaute-disponibilit√© Performances Co√ªts Les 3 s\u0026rsquo;influencent bien √©videmment mutuellement.\nPar exemples:\nSi la HA est un crit√®re dominante, les co√ªts vont forc√©ment grimper et les performances peuvent baisser (multi-r√©gions, multi-cloud). Si on privil√©gie les performances, des machines plus grosses seront √† payer mais la HA pourra √™tre sacrifi√©e √©galement (j\u0026rsquo;ai eu un client qui faisait tout tourner sur une seule AZ AWS car les latences entre les datacenters AWS avaient un impact sur sa grille de calcul). Si on cherche absolument √† baisser les co√ªts, on sacrifiera les performances et/ou la haute-disponibilit√©. Un autre crit√®re √† prendre en compte: la S√©curit√© J\u0026rsquo;ai volontairement omis de rajouter ce 4√®me crit√®re dans la liste pr√©c√©dente, car il est particulier et √† toute son importance. Il impacte potentiellement les 3 autres crit√®res et s\u0026rsquo;inscrit dans un cadre plus important tr√®s souvent impossible √† n√©gliger (PCI-DSS, HADS, etc). Il faut donc veiller √† ce que les recommandations s\u0026rsquo;inscrivent dans les bonnes pratiques de s√©curit√©, voire dans le cadre de la loi.\nAjuster ses crit√®res Il ressort de tout cela une bonne nouvelle, c\u0026rsquo;est que nous sommes dans le cadre d\u0026rsquo;une plateforme Cloud, qui vient avec ses contraintes mais aussi ses avantages, avec en t√™te de la liste la flexibilit√©.\nJ\u0026rsquo;ai mentionn√© pr√©c√©demment que tout l\u0026rsquo;art du FinOps √©tait de trouver le bon dosage entre les perfs, la HA et les co√ªts, et ce qu\u0026rsquo;il y a de magique avec le Cloud, c\u0026rsquo;est que ce dosage n\u0026rsquo;est pas vou√© √† √™tre immuable et universel. La souplesse des Cloud Providers permet d\u0026rsquo;ajuster la balance comme on le souhaite et quand on le souhaite.\nVoici une liste d\u0026rsquo;√©l√©ments pouvant amener √† adapter notre choix du ou des crit√®res dominants, avec quelques exemples pour les expliciter:\nEnvironnement: On accorde souvent plus d\u0026rsquo;importance √† la disponibilit√© de l\u0026rsquo;environnement de production qu\u0026rsquo;√† celui de staging. P√©riode: En e-commerce, on mettra le paquet en p√©riode de soldes. Une application de facturation n\u0026rsquo;a besoin d\u0026rsquo;√™tre gonfl√©e aux st√©ro√Ødes qu\u0026rsquo;en d√©but ou fin de mois, etc. Criticit√© des donn√©es: On peut parfois se permettre de perdre du cache, mais pas des donn√©es m√©tier. Criticit√© de l\u0026rsquo;application: Un SSO sera central, alors qu\u0026rsquo;un worker qui tombe ne cr√©e que du d√©lai et sa t√¢che sera cens√©e √™tre reprise ensuite. Enjeux Business: Respect des SLA de disponibilit√© ou de performance. Budget: Une lev√©e de fond permet souvent d\u0026rsquo;apporter les modifications voulues ou √† l\u0026rsquo;inverse, un trou dans la tr√©sorerie imposera de sacrifier tel ou tel crit√®re. Co√ªts et mod√®les de facturation Il est extr√™mement important d\u0026rsquo;avoir √† l\u0026rsquo;esprit de quoi sont compos√©es les factures mais aussi le contexte global dans lesquelles elles s\u0026rsquo;inscrivent.\nJe d√©gage donc 2 axes, les co√ªts Directs et les co√ªts Indirects.\nOn ne pourra pas jouer sur les deux de la m√™me fa√ßon, voire pas du tout pour certains √©l√©ments. Et il est tr√®s important de tous les prendre en compte dans les choix des actions √† mener.\nLes co√ªts Directs Je classe parmi les co√ªts Directs tout ce qui est directement dans la facture du Cloud Provider, en s√©parant en 2 cat√©gories:\nRessources: Ce sont les co√ªts dans les factures les plus simples √† comprendre et estimer, g√©n√©ralement factur√©s √† la seconde ou heure, ils caract√©risent les √©l√©ments \u0026ldquo;immobilis√©s\u0026rdquo; pour composer l\u0026rsquo;infrastructure (Instances, Volumes, etc). La r√®gle est simple, plus on prend gros, plus on paye cher, et inversement. On peut donc facilement estimer les √©conomies possibles quand on agit sur elles. Consommations: Ce sont tous les co√ªts dans les factures plus difficiles √† estimer car ind√©pendant de nos propres choix et variant du tout ou tout entre les p√©riodes. On y classe la bande passante, les snapshots, le nombre total de requ√™tes, etc. Les estimations d\u0026rsquo;√©conomies sont souvent moins pr√©cises mais en connaissant bien son activit√© et en prenant quelques marges, on y arrive. Les co√ªts Indirects Quand on pense √† r√©duire sa facture Cloud on oublie bien souvent les co√ªts annexes qui n\u0026rsquo;apparaissent pas √† proprement parl√© sur la facture mais qui sont pourtant bien l√† quand on veut mettre en place des actions:\nCo√ªts de migration: Si vous pr√©voyez de remplacer des morceaux ou de partir sur une nouvelle architecture, il sera n√©cessaire de passer un grand nombre de JH (jour-homme) sur le sujet, et cela aura un co√ªt pour votre organisation, tant financier qu\u0026rsquo;humain. Le retour sur investissements se doit donc d\u0026rsquo;√™tre int√©ressant. Co√ªts de d√©veloppement: Dans la m√™me id√©e, moins OPS et plus DEV, si vous changez de technologie, il y aura s√ªrement du code √† √©crire et donc du JH √† passer, sur des fonctionnalit√©s qui n\u0026rsquo;apportent pas forc√©ment une plus-value pour le client final. Formation: Un point √† ne jamais n√©gliger, tout changement sera mieux v√©cu s\u0026rsquo;il est accompagn√© par une formation, qu\u0026rsquo;elle soit interne ou non (c\u0026rsquo;est souvent plus cher avec des consultants ext√©rieurs, bien entendu). Infog√©rance: Si vous ne g√©rez pas vous-m√™me votre plateforme, ou si vous avez souscrit un contrat pour avoir du 24/7, le p√©rim√®tre financier peut √™tre impact√©. Licences: C\u0026rsquo;est un point surtout valable pour les migrations d\u0026rsquo;On-Premise vers du Cloud, les mod√®les de facturation des licences √©diteurs pouvant beaucoup changer, et pas forc√©ment √† la baisse. Ces co√ªts Indirects sont bien souvent plus difficiles √† √©valuer, voire quasi impossibles quand vous √™tes un auditeur externe, mais il est important de prendre en compte le fait qu\u0026rsquo;ils existent et peuvent drastiquement changer le choix des actions √† mener.\nFinOps, un processus Maintenant que nous avons la destination, voyons le chemin. A mon sens, le FinOps est un processus qui se d√©roulera toute la vie de la plateforme et d√©bute √† sa conception. Il appara√Æt bien souvent que r√©fl√©chir √† une architecture en int√©grant les aspects FinOps d√®s le d√©but, am√®ne √† cr√©er des conceptions plus proches des bonnes pratiques.\nCe processus √† plusieurs caract√©ristiques, il est:\nContinue It√©ratif (une action apr√®s l\u0026rsquo;autre) A complexit√© croissante (voire exponentielle) Ce processus, peut varier d\u0026rsquo;une entreprise √† l\u0026rsquo;autre, mais on retrouve g√©n√©ralement 3 √©tapes cl√©s, se r√©p√©tant:\nAnalyse \u0026gt; Recommandations \u0026gt; Mise en place \u0026gt; Analyse \u0026gt; \u0026hellip;\nUn processus continue Les architectures Cloud √©tant √©lastiques, les facturations associ√©es le sont tout autant. A cela s\u0026rsquo;ajoute que le tout virtualis√©, pay√© √† la consommation, rend les architectures mutables (changement de types de machines, remplacement de briques par d\u0026rsquo;autres services, etc). Il appara√Æt alors √©vident que mener des actions FinOps une fois tous les trimestres, par exemple, sera moins pertinent, et pire, √† la tra√Æne vis-√†-vis des d√©penses.\nIl est important d\u0026rsquo;int√©grer le FinOps parmi tous les autres processus permettant de g√©rer correctement une plateforme, voire m√™me d\u0026rsquo;int√©grer des points de contr√¥le au m√™me titre que nous mettons en place du monitoring pour les syst√®mes eux-m√™mes. Les Cloud Providers ne s\u0026rsquo;y sont pas tromp√©s et fournissent des moyens de v√©rifier le respect d\u0026rsquo;un budget (sans jamais bloquer les possibles d√©penses, on parle juste d\u0026rsquo;alertes). Cela rentre dans la partie de ma d√©finition: limiter les co√ªts.\nCela n\u0026rsquo;√©carte pas les audits plus profonds pouvant √™tre men√©s, non pas au jour le jour, mais tout de m√™me r√©guli√®rement, et qui eux servent souvent √† d√©gager les axes d\u0026rsquo;√©conomies plus importantes.\nUn processus it√©ratif Une fois qu\u0026rsquo;une analyse FinOps a √©t√© men√©e √† bien et que des pr√©conisations ont √©t√© √©tablies, la tentation de r√©duire la facture imm√©diatement peut √™tre forte en menant toutes les actions d\u0026rsquo;un coup. C\u0026rsquo;est rarement une bonne chose. En menant plusieurs actions en parall√®le, il devient plus difficile de d√©terminer quelles sont celles qui ont eu l\u0026rsquo;effet escompt√©, et pire, certaines peuvent entrer en contradiction sans qu\u0026rsquo;il ne soit possible de d√©terminer comment. En it√©rant, action par action, il devient ais√© de d√©terminer celles qui ont bien fonctionn√© et donc de les r√©p√©ter dans le temps ou sur d\u0026rsquo;autres environnements.\nUn processus √† complexit√© croissante La premi√®re action (cf suite de l\u0026rsquo;article) est g√©n√©ralement de traquer les d√©penses inutiles, les g√¢chis. C\u0026rsquo;est une action relativement simple, qu\u0026rsquo;on peut faire manuellement dans un premier temps puis automatis√©e. Une fois que c\u0026rsquo;est en place, d\u0026rsquo;autres actions peuvent √™tre men√©es, forc√©ment plus compliqu√©es que les pr√©c√©dentes, et ainsi de suite. Il appara√Æt rapidement que le rapport √©conomies possibles sur investissement (temps + argent) s\u0026rsquo;amenuise avec le temps, plus on avance dans les solutions trouv√©es pour limiter les co√ªts ou √©conomiser, plus celles-ci deviennent complexes √† mettre en oeuvre. Je pense m√™me que la tendance suivie est exponentielle. L\u0026rsquo;ordre de grandeur de l\u0026rsquo;investissement n\u0026rsquo;est pas du tout le m√™me entre une automatisation de la suppression des volumes d√©tach√©s et la refonte d\u0026rsquo;une partie de l\u0026rsquo;infrastructure pour utiliser du Serverless.\nOutillage Avec quoi pouvons-nous mener une analyse FinOps?\nIl s\u0026rsquo;agit bien entendu d\u0026rsquo;une liste non exhaustive, mais c\u0026rsquo;est une demande qui m\u0026rsquo;a souvent √©t√© fa√Æte donc la voici.\nLes Factures Les factures sont, bien entendu, les premi√®res pi√®ces √† √©tudier, elles sont souvent simplifi√©es et permettent d\u0026rsquo;avoir un aper√ßu global ainsi que les tendances. C\u0026rsquo;est aussi ce que re√ßoit votre service comptabilit√© (√ßa aidera pour communiquer avec eux, pour lui expliquer les possibles pics ou autres quand c\u0026rsquo;est n√©cessaire).\nAWS Cost Explorer/Trusted Advisor AWS fournit 2 outils:\nCost Explorer: Cela va √™tre votre nouvel meilleur ami. L\u0026rsquo;outil s\u0026rsquo;am√©liore d\u0026rsquo;ann√©e en ann√©e et vous permet d\u0026rsquo;analyser et de mettre en graphique tout votre historique de d√©penses, de filtrer par tags, service, r√©gion, etc. C\u0026rsquo;est vraiment un indispensable et il faut vraiment apprendre √† s\u0026rsquo;en servir. La difficult√© est de comprendre ce qu\u0026rsquo;on lit, car contrairement aux factures, les d√©tails se basent sur l\u0026rsquo;API AWS et non une simplification des termes comme dans les factures re√ßues en fin de mois. Trusted Advisor: Lorsque vous souscrivez au support de niveau Business, en plus de donner de bonnes informations li√©es √† la s√©curit√© de votre plateforme, l\u0026rsquo;outil vous donne des informations sur les g√¢chis financiers pr√©sents dans le compte. La n√©cessit√© d\u0026rsquo;avoir un haut niveau de support pour que ce soit actif peut √™tre contraignant mais heureusement, les √©l√©ments donn√©s sont relativement simples √† obtenir √† la main ou via script. Les Scripts Il existe une pl√©thore de scripts voire d\u0026rsquo;applications compl√®tes sur le web pour aider √† analyser ses co√ªts et trouver les axes d\u0026rsquo;am√©lioration. Vous pouvez √©galement √©crire vos propres scripts pour mettre en avant des points pr√©cis li√©s √† votre infrastructure. L\u0026rsquo;avantage de l\u0026rsquo;automatisation est bien entendu de vous faire gagner du temps mais surtout de pouvoir avoir des r√©sultats r√©guliers et donc de suivre les r√©sultats de vos modifications.\nVoici quelques exemples (les deux premiers sont de moi):\ngo-s3-describe aws-inventory-graph komiser Et une recherche sur Github avec quelques autres outils: R√©sultats\nSaaS L\u0026rsquo;engouement pour le FinOps vient forc√©ment avec son lot de services en ligne pour aider dans la t√¢che, en voici deux que j\u0026rsquo;ai test√©s (je ne ferai pas de comparatif, n\u0026rsquo;y ayant pas touch√© depuis longtemps maintenant):\nCloudhealth Cloudcheckr Ces outils font plus que du FinOps, mais comme leurs co√ªts rentrent dans ce que j\u0026rsquo;appelle les co√ªts Indirects, il faut donc les prendre en compte dans vos calculs pour estimer les √©conomies.\nWebsites Le web fourmille de documentations et d\u0026rsquo;articles comme celui-ci, il ne faudra pas h√©siter √† chercher des heures durant pour apprendre les techniques en vogue pour limiter les co√ªts ou m√™me d√©coder la documentation AWS parfois absconde.\nVoici un exemple d\u0026rsquo;outils que l\u0026rsquo;on peut trouver et utiliser fr√©quemment:\nhttps://Instances.vantage.sh https://calculator.aws/#/ (calculateur officiel fourni par AWS) https://observablehq.com/@rustyconover/aws-ec2-spot-Instance-simulator Sch√©mas Le FinOps est un travail technique, m√™me si on √©pluche bien les factures, il est int√©ressant d\u0026rsquo;avoir la vision de la plateforme en terme d\u0026rsquo;architecture. Comprendre comment les choses sont pens√©es, de l\u0026rsquo;Instance aux services manag√©s. Le nec plus ultra √©tant d\u0026rsquo;avoir √©galement les flux r√©els et pas juste un sch√©ma de principe, les flux √©tant souvent tr√®s difficiles √† cat√©goriser et encore plus √† comprendre niveau facturation.\nVoici un sch√©ma de quelques flux avec les sens pour lesquels AWS vous facture:\nLa M√©trologie Tous les Cloud Providers fournissent leurs propres solutions de m√©trologie, plus ou moins avanc√©es. Dans le cas d\u0026rsquo;AWS, la solution s\u0026rsquo;appelle Cloudwatch. Bien que pratiques, il est n√©cessaire, pour √©valuer le bon usage des ressources, d\u0026rsquo;avoir son propre syst√®me de m√©trologie, avec une granularit√© plus fine, mais surtout plus de m√©triques. Prenons le cas de l\u0026rsquo;utilisation CPU, qui est certes rarement un facteur limitant sur des services Web, l\u0026rsquo;utilisation de la m√©moire ou les IO √©tant plus √† suivre. Vous n\u0026rsquo;avez aucune information sur les contextes d\u0026rsquo;ex√©cution (user, system, steal, iowait, \u0026hellip;). Dans le cas de la RAM, votre Cloud Provider ne vous fournira pas de d√©tails sur son utilisation, difficile de juger en l\u0026rsquo;√©tat de la pertinence de sa taille pour vos besoins.\nBeaucoup d\u0026rsquo;actions possibles La liste suivante d\u0026rsquo;actions cat√©goris√©es FinOps ne se veut absolument pas compl√®te, chaque service ayant ses sp√©cificit√©s et les mod√®les de facturation √©voluant aussi dans le temps. Encore une fois, m√™me si tr√®s orient√© AWS, elles sont tout ou en partie transposables √† d\u0026rsquo;autres Cloud Providers.\nCat√©goriser les actions √† entreprendre Afin de pouvoir mieux √©valuer les pertinences des actions pr√©conis√©es mais aussi de pouvoir les prioriser, j\u0026rsquo;ai pris l\u0026rsquo;habitude de les cat√©goriser selon 3 crit√®res:\nComplexit√©: C\u0026rsquo;est souvent un bon moyen pour aider √† estimer le temps qui sera n√©cessaire pour la mise en oeuvre. Risque: Notre but, comme explicit√© dans ma d√©finition, est de ne pas d√©grader la production, mais toute action √† sa part de risque, surtout lors d\u0026rsquo;une bascule d\u0026rsquo;un morceau d\u0026rsquo;architecture √† une autre, ou bien lors de la r√©duction du type d\u0026rsquo;une Instance. Economies attendues: En valeur absolue bien souvent, et √† mettre en perspective avec les deux autres crit√®res. Il peut √™tre pertinent de faire une action simple, sans risque qui fait √©conomiser $100 plut√¥t qu\u0026rsquo;une refonte compliqu√©e qui fera gagner $200 mais demandera 10JH par ailleurs (rappelez-vous, les co√ªts Indirects). Lorsque l\u0026rsquo;audit FinOps est pour un client tiers, cela sera d\u0026rsquo;autant plus important de lui permettre d\u0026rsquo;√©valuer les actions qu\u0026rsquo;il voudra mener ou faire mener, lui seul ayant les cordons de sa bourse.\nIdentifier et supprimer les g√¢chis La premi√®re action √† laquelle on pense, est bien √©videmment de r√©duire les g√¢chis. La flexibilit√© du Cloud amenant souvent √† cr√©er puis laisser tra√Æner des ressources dans un coin.\nVoici une liste de quelques g√¢chis communs:\nSnapshots anciens: Plusieurs cas de figures, soit ce sont des Snapshots pour des AMI obsol√®tes, soit de volumes EBS n\u0026rsquo;existant plus. Il se peut que ce soit de vieux Snapshots d\u0026rsquo;EBS encore en fonctionnement, dans ce cas, comme ils sont sauvegard√©s de mani√®re incr√©mentale, leurs suppressions entra√Æneront un gain moins important sur la facture, les plus r√©cents ayant toujours besoin d\u0026rsquo;une r√©f√©rence. AMI Anciennes: Sauf si cela s\u0026rsquo;av√®re vraiment n√©cessaire, il n\u0026rsquo;est pas utile de garder de vieilles AMI, avec des syst√®mes et des paquets obsol√®tes. Leurs suppressions ne font rien gagner √† proprement parl√©, mais lib√®rent des Snapshots qui eux peuvent ensuite √™tre supprim√©s. EIP d√©tach√©es: Le gain est minime, mais si vraiment elles ne servent √† rien, autant les lib√©rer. EBS d√©tach√©s: Cela vient souvent de la suppression d\u0026rsquo;Instances sans suppression des volumes qui les utilisaient. Si en plus il y avait de l\u0026rsquo;AutoScaling d\u0026rsquo;actif, les volumes peuvent vite monter. EBS attach√©s mais sans IO: Le coup classique du volume mont√© sur /logs mais o√π aucune application n\u0026rsquo;√©crit dedans. ELB/ALB/NLB sans Instance ou sans requ√™te: Il arrivent que des xLB ne pointent vers rien, ou bien que les Instances derri√®res soient Unhealthy depuis tr√®s longtemps, sans aucun impact par ailleurs. EC2/RDS dans des anciens types: A chaque nouvelle famille sortie par AWS, les prix sont plus faibles, pour parfois de meilleures performances ou options. EC2 stopp√©es depuis longtemps: Le compute n\u0026rsquo;est pas pay√© dans ce cas, seul le stockage, cela peut √™tre l√©gitime ou non. A vous de voir. Buckets S3 avec des objets de type Reduced Redundancy Storage Class: AWS a d√©pr√©ci√© ce type d\u0026rsquo;objet, en le rendant l√©g√®rement plus ch√®re d\u0026rsquo;un milli√®me que le type Standard, sur des Po voire To, cela vite (histoire v√©cue avec une plateforme de streaming de musique) Buckets S3 Buckets qui sont Publics mais pas derri√®re une distribution CloudFront: Rien que le fait de sortir sur Internet √† travers une distribution Cloudfront r√©duit les co√ªts de bande passante, cache activ√© ou non. Ceci est valable dans tous les cas, devant xLB ou EC2. RDS sans connexion depuis longtemps: Si la base ne sert que de temps en temps, il est toujours possible de l\u0026rsquo;√©teindre (pour 7j maximum, ensuite il faudra √©teindre de nouveau). RDS utilisant du PIOPS inutile: Pour chaque GB de GP2/3, AWS assure un plancher de 3 IOPS, ce qui implique qu\u0026rsquo;avec 350GB, vous avez plus (1050 IOPS) que les 1000 IOPS demand√©s √† √™tre pay√©s en minimum pour le stockage PIOPS, et ce pour beaucoup moins cher. Pour vous aider √† identifier ces √©l√©ments, l\u0026rsquo;API et les m√©triques en votre possession seront tr√®s utiles.\nUtiliser correctement les ressources Les ressources manag√©es Avec l\u0026rsquo;av√®nement du Cloud, sa souplesse et sa rapidit√© pour obtenir des ressources, on en vient presque √† oublier les r√©flexes de nos pr√©d√©cesseurs, contraints √† tirer jusqu\u0026rsquo;√† la derni√®re goutte de s√®ve des machines achet√©es pour plusieurs ann√©es. Je crois fermement, qu\u0026rsquo;avant d\u0026rsquo;entamer des changements de type, surtout lors de Scale Up (augmentation du type), il faut travailler au niveau de l\u0026rsquo;OS et des applications pour obtenir le maximum. Tout r√©soudre par de l\u0026rsquo;infra n\u0026rsquo;a jamais √©t√© pertinent (le fameux plus de RAM, toujours plus de RAM, au lieu de traiter la fuite m√©moire).\nL\u0026rsquo;OS et les Applications Dans le cas des ressources manag√©es, surtout RDS, de tr√®s nombreux r√©glages sont √† disposition pour param√©trer les moteurs (taille des buffers, allocation de tables temporaires, nombre max de connexions, etc). Les ajuster au r√©el besoin m√©tier peut parfois changer du tout au tout les performances.\nPour les EC2, c\u0026rsquo;est encore plus vrai, car on peut jouer sur bien plus de r√©glages comme:\nles param√®tres sysctl: Tous les OS Unix-Like permettent de r√©gler des param√®tres du kernel, dont beaucoup de limites. En ajustant ces valeurs, on peut souvent repousser les capacit√©s utilisables. les configurations des applications: La majorit√© des applications, surtout dans le monde du Web OpenSource, permettent d\u0026rsquo;√™tre configur√©es jusqu\u0026rsquo;au plus petit d√©tails pour assurer leurs charges (worker_processes ou keepalives pour Nginx par exemple). Compiler ses binaires Une autre option, bien moins r√©pandue, car plus difficile √† mettre en oeuvre, est le fait d\u0026rsquo;utiliser des binaires compil√©s pour l\u0026rsquo;architecture CPU de l\u0026rsquo;EC2 utilis√©e. Cela peut para√Ætre farfelu, surtout que cela apporte une grande complexit√© et sort totalement du cadre des gestionnaires de paquets si pratiques. Mais apr√®s tout, utiliser des binaires compil√©s en dehors de toute arborescence, c\u0026rsquo;est une chose tr√®s r√©pandue, et cela s\u0026rsquo;appelle un Container üòâ. AWS fournit pour chaque type d\u0026rsquo;Instance le mod√®le de CPU associ√©, √† votre charge de trouver les bons flags √† utiliser pour la compilation, et de penser √† les modifier √† chaque changement de type (par un exemple, un rendu Blender via le CPU peut gagner jusqu\u0026rsquo;√† 30% de temps [du v√©cu], imaginez pour la capacit√© de traitements de requ√™tes par un Apache ou Nginx/PHP-FPM).\nUtiliser les services manag√©s Utiliser des services manag√©s a un co√ªt, c\u0026rsquo;est ind√©niable, mais ils sont √† relativiser et √† mettre en perspective avec les co√ªts Indirects. Entre un PostgreSQL manag√© et un PostgreSQL install√© √† la main sur un serveur lou√©, il se peut que la solution du Cloud Provider soit plus ch√®re, mais si vous rajoutez dans votre solution maison les co√ªts financiers et humains pour la gestion des backups, des possibles restaurations, de la haute disponibilit√©, etc, sans avoir en plus forc√©ment la capacit√© de changer la taille de la machine ou agrandir son stockage, la balance ne penche plus du m√™me c√¥t√©. Encore une fois, s\u0026rsquo;arr√™ter uniquement aux co√ªts mat√©riels (qui se rattachent aux co√ªts Directs) et ne pas prendre l\u0026rsquo;ensemble du p√©rim√®tre financier, peut s\u0026rsquo;av√©rer contre-productif.\nMettre en place des outils, des proc√©dures, des formations Je conseille g√©n√©ralement de commencer par tout faire manuellement, que ce soit l\u0026rsquo;analyse des co√ªts dans le Cost Explorer, la recherche des g√¢chis ou l\u0026rsquo;estimation des √©conomies possibles. Cela dans le but de vraiment comprendre comment les choses fonctionnent et de pouvoir rep√©rer d\u0026rsquo;un coup d\u0026rsquo;oeil des axes d\u0026rsquo;am√©liorations une fois que l\u0026rsquo;habitude est fa√Æte. Une fois rod√©, il est temps de mettre en place des proc√©dures, et si possible des outils automatis√©s pour limiter les d√©rives dans le temps. L\u0026rsquo;automatisation des proc√©dures de nettoyage et d\u0026rsquo;extinction des environnements en dehors des heures ouvr√©es sont des grands classiques, on trouve de nombreux exemples sur le net. Comme √©voqu√© plus haut, c\u0026rsquo;est √† ce niveau que les alertes de Budget peuvent aussi apporter leurs aides, m√™me si elles peuvent souvent s\u0026rsquo;av√©rer trop rigides (une p√©riode de soldes peut exploser les compteurs par rapport au mois d\u0026rsquo;avant, sans que cela soit inqui√©tant, bien au contraire). Un volet √† ne pas n√©gliger √† cette √©tape (√† toutes en fait), est de former les √©quipes (chez soi ou chez son client), √† ce qu\u0026rsquo;est le FinOps, ce qu\u0026rsquo;il apporte et sur les proc√©dures en cours dans l\u0026rsquo;entreprise qui font partie de son processus.\nArchitecturer pour r√©duire les co√ªts C\u0026rsquo;est la m√©thode la plus complexe, mais souvent la plus efficace et gratifiante, la refonte. Les Cloud Providers sortent en permanence de nouvelles fonctionnalit√©s et nouveaux services, ce qui est impossible aujourd\u0026rsquo;hui ne le sera possiblement plus dans 1 ou 2 ans. Int√©grer le FinOps lors de la conception d\u0026rsquo;une plateforme est important pour √™tre efficient, mais cela l\u0026rsquo;est encore plus lors des refontes, qui peuvent souvent √™tre dict√©es pour des raisons de rationalisation et/ou d\u0026rsquo;√©conomies. Cela est d\u0026rsquo;autant plus pertinent que vous avez alors une vraie exp√©rience du comportement de votre plateforme, de ses besoins et contraintes.\nOn peut envisager dans le cas d\u0026rsquo;une refonte de:\nmigrer certaines fonctions dans Lambda utiliser DynamoDB en base NoSQL utiliser des ALB devant les Lambda et non des API Gateway Il faut garder √† l\u0026rsquo;esprit encore une fois, que toutes les actions ont des co√ªts Indirects (JH pour migrer le code d\u0026rsquo;une solution technique √† une autre, formations, etc), et peuvent vous \u0026ldquo;verrouiller\u0026rdquo; chez un Cloud Provider, on touche l√†, √† la politique de l\u0026rsquo;entreprise.\nPolitiqes de Scale In/Out La capacit√© d\u0026rsquo;adapter la flotte de machines √† la charge est une fonctionnalit√© de base, c\u0026rsquo;est presque la raison premi√®re de l\u0026rsquo;existence du Cloud. Avec le temps, que ce soit en natif ou via des fonctions externes, on peut piloter les groupes d\u0026rsquo;AutoScaling pour faire beaucoup de choses comme:\nRetirer tout ou partie des machines en dehors des heures ouvr√©es Changer la taille des Instances en fonction des p√©riodes Scale In/Out (ajouter/retirer) en fonction de m√©triques m√©tiers et non juste le CPU (qui est rarement une m√©trique pertinente, je le rappelle) R√©servations / Saving Plans Si vous √™tes pr√™t √† vous engager sur du long terme (1 ou 3 ans), r√©server des ressources est le moyen le plus direct d\u0026rsquo;obtenir au moins 30% d\u0026rsquo;√©conomie (avec versement d\u0026rsquo;un account ou non) sur des services tels que:\nEC2 RDS Elasticache DynamoDB Les cas de DynamoDB et Elasticache sont un peu particulier, le premier demandant de r√©server des capacit√©s en Read/Write et non des ressources \u0026ldquo;mat√©rielles\u0026rdquo; et le second imposant un acompte dans tous les cas.\nPour rappel, les r√©servations fonctionnent avec des unit√©s de temps, il ne s\u0026rsquo;agit pas de machines avec une √©tiquette √† son nom dans le datacenter AWS.\nPrenons un exemple pour expliciter les choses.\nImaginons que vous r√©serviez pour 1 an, pour de l\u0026rsquo;EC2, 1 \u0026ldquo;Instance\u0026rdquo; m5.xlarge. Vous obtenez donc, 4 unit√©s (cf ce tableau) par mois dans la famille m5. En prenant qu\u0026rsquo;un mois fait en moyenne 732h, vous aurez donc le droit au prix r√©duit pour:\n732h de m5.xlarge 1464h de m5.large (soit 2 Instances) 366h de m5.2xlarge (soit 1 Instance allum√©e la moiti√© du mois) Les unit√©s sont circonscrites √† une famille, c\u0026rsquo;est exactement le m√™me cas pour les Saving Plans de type EC2 Instance (les √©conomies sont √† la virgule pr√®s les m√™mes que pour les R√©servations). Si vous voulez ne pas √™tre contraint, et ne raisonner qu\u0026rsquo;en termes d\u0026rsquo;unit√©s de calcul et non de \u0026ldquo;famille\u0026rdquo;, les Saving Plans de type Compute, sont la nouvelle m√©thode pour proc√©der √† des r√©servations chez AWS, peu importe la famille ou le type. Les r√©ductions sur le Compute s\u0026rsquo;appliquant peu importe le type, cela vous permet de changer de famille quand vous le souhaitez. Cela vient cependant avec une √©conomie moindre.\nSpot Instances AWS met √† disposition son stock d\u0026rsquo;invendus (en quelque sorte) √† prix cass√© (jusqu\u0026rsquo;√† -70%), ce qu\u0026rsquo;ils appellent des Spot Instances. Le principe est simple, vous d√©finissez un prix maximal pour lequel vous √™tes pr√™t √† payer, et tant que le prix courant est inf√©rieur et qu\u0026rsquo;AWS a du stock, vous √™tes susceptible d\u0026rsquo;avoir votre Instance. Si un des crit√®res n\u0026rsquo;est plus respect√©, AWS vous pr√©vient 2min avant de vous retirer l\u0026rsquo;Instance. Pour mitiger les risques, vous avez la possibilit√© de vous faire des flottes, c\u0026rsquo;est-√†-dire des groupes d\u0026rsquo;Instances de diff√©rents types.\nC\u0026rsquo;est un moyen extr√™mement puissant pour faire des √©conomies, √† condition que l\u0026rsquo;usage que vous en fa√Ætes tol√®re de perdre des noeuds, c\u0026rsquo;est donc tr√®s souvent utilis√© pour faire des tests au sein d\u0026rsquo;une CI, par exemple.\nUn autre aspect √† prendre en compte et qui permet de limiter encore plus les risques, c\u0026rsquo;est de mixer des Instances On-Demand (pay√©es au prix public annonc√©) et des Instances Spot. C\u0026rsquo;est d√©sormais possible avec les Launch Templates qui d√©finissent comment doivent √™tre les Instances d\u0026rsquo;un groupe d\u0026rsquo;Auto-Scaling. Vous d√©finissez le nombre d\u0026rsquo;Instances On-Demand qui constitueront votre base, puis le pourcentage d\u0026rsquo;On-Demand au dessus cette base par rapport aux Instances Spot. Si votre base On-Demand correspond √† vos r√©servations, l\u0026rsquo;√©conomie est encore plus importante avec un risque contr√¥l√©.\nOrganisation des comptes La bonne pratique est d\u0026rsquo;isoler les environnements (prod, staging, etc) dans des comptes AWS diff√©rents. Isoler les comptes les uns des autres permet, entre autres:\nd\u0026rsquo;assurer l\u0026rsquo;√©tanch√©it√© pour la s√©curit√© de bien s√©parer les co√ªts, ce qui facilite les analyses (un flux sortant est un flux sortant, AWS ne vous dira pas de quelle VPC pr√©cis√©ment il vient, difficile de refacturer entre cost centers dans ce cas) A c√¥t√© de cela il est tr√®s int√©ressant de regrouper tous ces comptes au sein d\u0026rsquo;une seule organisation, avec un compte payeur identifi√© (appel√© compte consolidant) et ne poss√©dant aucune ressource (pour simplifier les analyses, de cette mani√®re il n\u0026rsquo;appara√Ætra pas 2 fois, en tant que compte et compte consolidant).\nIl y a plusieurs avantages √† faire cela, le compte payeur agr√©geant la totalit√© de la facture:\nles r√©servations sont remont√©es au niveau du compte consolidant (sauf param√©trage volontaire), ce qui implique que les unit√©s non utilis√©es d\u0026rsquo;un c√¥t√© peuvent l\u0026rsquo;√™tre de l\u0026rsquo;autre, vous ne payez pas pour rien vous b√©n√©ficiez des tarifs sur les volumes (au sens de quantit√©), ce qu\u0026rsquo;on appelle les Blended Costs. AWS fournit une facture r√©capitulative de l\u0026rsquo;ensemble des frais, ce qui fera plaisir au service comptable qui n\u0026rsquo;aura pas √† g√©rer N pdf. Les Blended Costs sont une mani√®re d\u0026rsquo;agr√©ger tous les volumes de certains services et de b√©n√©ficier ainsi des tranches de prix inf√©rieures.\nPrenons comme exemple S3 pour expliciter la chose.\nImaginons deux comptes li√©s A et B √† un compte consolidant Z. Les usages S3 sont respectivement:\n50To en eu-west-3 pour le compte A 30To en eu-west-3 pour le compte B Si les comptes √©taient factur√©s s√©par√©ment, il devraient:\ncompte A: 40To x 0,024$/GB = $960 compte B: 30To x 0,024$/GB = $720 total: $1680 Avec les Blended Costs, le compte Z consolidant le tout paiera en fait:\n50To x 0,024$/GB + 20To x 0,023$/GB = $1620 Le principe sous-jacent √©tant que pour S3, en eu-west-3, les 50 premiers To valent 0,024$/GB et 0,023$/GB au del√†.\nOn a donc une √©conomie de $60, sans aucune action autre qu\u0026rsquo;avoir li√© les comptes A et B √† Z.\n(voir ICI pour les tarifs de S3)\nTags On touche au nerf de la guerre, les Tags. Il est essentiel pour comprendre les co√ªts, voire de les anticiper, de cat√©goriser au maximum les choses, et cela passe par le tagging des ressources qui le peuvent (on ne peut pas tagger les flux r√©seau, par exemple).\nVoici quelques tags utiles:\nenvironnement project businessUnit costCenter scope team Il y a un point tr√®s important √† savoir, les tags sont sensibles √† la casse au niveau des cl√©s et des valeurs, il faut donc √™tre vigilant pour ne pas avoir des prod, Prod, production, etc, qui repr√©sentent la m√™me valeur mais cr√©ent du bruit, voire peuvent cacher certaines ressources de vos rapports.\nPour vous aider dans votre rattrapage, dans le cas o√π vous avez des ressources cr√©√©es √† la main, AWS fournit un outil au final assez m√©connu, le Tag Editor.\nConclusion Cet article n\u0026rsquo;est finalement qu\u0026rsquo;une √©bauche de tout ce qu\u0026rsquo;on peut faire sans vraiment rentrer dans les d√©tails de comment on le fait. Il ne repr√©sente qu\u0026rsquo;une synth√®se de mes r√©flexions, dont les conclusions sont s√ªrement discutables (et peut-√™tre obsol√®tes maintenant, le monde du Cloud bougeant tellement vite). Vous avez s√ªrement remarqu√© qu\u0026rsquo;il y a un grand absent dans cet article, quid du FinOps quand on utilise Kubernetes? A l\u0026rsquo;√©poque o√π je faisais encore des audits FinOps, bien qu\u0026rsquo;utilisant K8S en production, je n\u0026rsquo;avais jamais eu √† creuser s√©rieusement la question. Je pense cependant que les principes g√©n√©raux que j\u0026rsquo;ai mentionn√©s peuvent s\u0026rsquo;appliquer en partie, dans le cas d\u0026rsquo;un environnement avec des ressources mutualis√©es comme l\u0026rsquo;est Kubernetes.\nMerci d\u0026rsquo;avoir lu jusqu\u0026rsquo;au bout ce long article, et j\u0026rsquo;esp√®re qu\u0026rsquo;il aura √©t√© utile √† quelqu\u0026rsquo;un, il m\u0026rsquo;a au moins permis de sortir de ma t√™te quelque chose qui y tra√Ænait depuis longtemps.\nEnjoy\n","date":"2021-06-17T00:00:00Z","permalink":"https://thomas.labarussias.fr/posts/finops/","title":"Le FinOps"},{"content":"J\u0026rsquo;ai enregistr√© il y a quelques jours une pr√©sentation traitant de falco et falcosidekick pour un Meetup CNCF Paris. J\u0026rsquo;y aborde ce que sont falco et falcosidekick et je montre comment on peut se servir des outputs de falcosidekick pour r√©agir en cas de d√©tection de comportements suspects.\nEnjoy\n","date":"2021-04-06T00:00:00Z","image":"https://thomas.labarussias.fr/img/falco-feature.png","permalink":"https://thomas.labarussias.fr/posts/cncf-meetup-paris-mars-2021/","title":"Falco: D√©tection et r√©action aux menaces dans Kubernetes"},{"content":"R√©cemment, apr√®s plusieurs jours en production, nous avons d√©tect√© au boulot que notre pod Cercat semblait avoir une memory leak.\nRien de complexe dans notre cas (ouf), cela a facilement √©t√© r√©gl√© √† coup de profiles Go mais une question s\u0026rsquo;est pos√©e : \u0026ldquo;Aurais-je pu le d√©tecter avant d\u0026rsquo;envoyer en prod en sachant que l\u0026rsquo;√©volution de la consommation m√©moire √©tait relativement lente?\u0026rdquo;\nJe me suis donc mis en t√™te d\u0026rsquo;avoir une solution cl√© en main pour monitorer en local une application Go lors de son d√©veloppement.\nL\u0026rsquo;id√©e, tr√®s simple au final, est d\u0026rsquo;utiliser une instance de Netdata dans un Docker qui appelle l\u0026rsquo;endpoint expvar de mon application Go.\nMicro tuto pour comprendre le principe :\nPr√©parer notre application\nUn micro code pour l\u0026rsquo;exemple :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import ( \u0026#34;expvar\u0026#34; // package pour exposer les m√©triques Go par d√©faut et notre m√©trique custom \u0026#34;math/rand\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) func main() { fake := expvar.NewFloat(\u0026#34;custom.fake\u0026#34;) // une m√©trique custom compl√®tement fausse go http.ListenAndServe(\u0026#34;:1111\u0026#34;, nil) // on d√©marre un serveur http sur le port 1111 for { // une boucle qui met √† jour al√©atoirement notre m√©trique custom fake.Set((rand.Float64() * 10) - 5) time.Sleep(time.Duration(rand.Intn(3)) * time.Second) } } Le code est comment√© pour comprendre √† quoi sert chaque ligne.\nOn pr√©pare la configuration de Netdata\ngo_expvar.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026#39;golang-app\u0026#39;: name : \u0026#39;golang-app\u0026#39; # le nom de notre app Go dans Netdata url : \u0026#39;http://golang-app:1111/debug/vars\u0026#39; # le port est √† adapter en fonction de l\u0026#39;application collect_memstats: true # on active la collecte des m√©triques m√©moires extra_charts: # la collecte de notre m√©trique custom - id: \u0026#34;custom\u0026#34; options: name: fake title: \u0026#34;custom\u0026#34; units: no-unit family: custom context: expvar.custom.fake chart_type: line lines: - {expvar_key: \u0026#39;custom.fake\u0026#39;, expvar_type: float, id: custom_fake} python.d.conf\n1 go_expvar: yes # active le monitoring des applications Go On d√©marre le tout via docker-compose\ndocker-compose.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 --- version: \u0026#34;3\u0026#34; services: netdata: image: netdata/netdata:latest container_name: netdata ports: - \u0026#34;19999:19999\u0026#34; volumes: - \u0026#34;${PWD}/python.d.conf:/etc/netdata/python.d.conf:ro\u0026#34; # pour activer le monitoring des applications GO - \u0026#34;${PWD}/go_expvar.conf:/etc/netdata/python.d/go_expvar.conf:ro\u0026#34; # pour configurer la collecte des m√©triques des applications Go - \u0026#34;/etc/passwd:/host/etc/passwd:ro\u0026#34; - \u0026#34;/etc/group:/host/etc/group:ro\u0026#34; - \u0026#34;/proc:/host/proc:ro\u0026#34; - \u0026#34;/sys:/host/sys:ro\u0026#34; - \u0026#34;/var/run/docker.sock:/var/run/docker.sock:ro\u0026#34; # pour moniter le Docker Go cap_add: - SYS_PTRACE security_opt: - apparmor:unconfined golang-app: image: golang:alpine container_name: golang-app ports: - \u0026#34;1111:1111\u0026#34; # le port d\u0026#39;√©coute de notre application, √† adapter volumes: - \u0026#34;${PWD}:/app\u0026#34; working_dir: /app command: go run main.go # la commande pour lancer l\u0026#39;application, √† adapter Le plus important est d\u0026rsquo;adapter le port d\u0026rsquo;√©coute et la commande de d√©marrage en fonction de votre application.\nOn d√©marre tout :\n1 docker-compose -f docker-compose.yaml up -d On v√©rifie que tout est bien d√©marr√© :\n1 2 3 4 5 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 5f9a07fa2e1f netdata/netdata:latest \u0026#34;/usr/sbin/run.sh\u0026#34; About a minute ago Up About a minute (healthy) 0.0.0.0:19999-\u0026gt;19999/tcp netdata 4e9d30d12bec golang:alpine \u0026#34;go run main.go\u0026#34; 5 days ago Up About a minute 0.0.0.0:1111-\u0026gt;1111/tcp golang-app L\u0026rsquo;instance Netdata est accessible via http://localhost:19999.\nApr√®s quelques secondes on obtient nos m√©triques.\nLes m√©triques du container de notre application :\nLes m√©triques expvar de notre application :\nNotre m√©trique custom :\nMettre √† jour notre application\nC\u0026rsquo;est tr√®s simple, il suffit de red√©marrer le container Go :\n1 $ docker restart 4e9d30d12bec Enjoy\n","date":"2020-06-27T00:00:00Z","permalink":"https://thomas.labarussias.fr/posts/monitorer-golang-app-local/","title":"Monitorer son application Go en local"},{"content":"En cette p√©riode de confinement, les phishers s\u0026rsquo;en donnent √† coeur joie. La question qui se pose alors est : Comment les d√©tecter le plus t√¥t possible?\nComme les sites de phishing servent souvent √† r√©cup√©rer des donn√©es confidentielles (n¬∞ de carte, mots de passe, etc), ils profitent de toutes les m√©thodes r√©centes pour r√©cup√©rer des certificats gratuits afin de se donner une belle image avec un joli cadenas dans la barre d\u0026rsquo;URL.\nQuelques recherches sur ce sujet m\u0026rsquo;a fait d√©couvrir un superbe projet de chez Calidog : CertStream. Ils mettent √† disposition un flux donnant en temps r√©el les certificats √©mis par Let\u0026rsquo;s Encrypt, Cloudflare, AWS, \u0026hellip;\nIl ne reste plus qu\u0026rsquo;√† s\u0026rsquo;y connecter, faire une correspondance des domaines avec une regexp pour avoir en temps r√©el, les possibles sites de phishing.\nD\u0026rsquo;autres ont eu la m√™me id√©e : CertStreamMonitor mais les performances m\u0026rsquo;ont d√©√ßu (100% d\u0026rsquo;utilisation permanente d\u0026rsquo;un CORE) et j\u0026rsquo;ai trouv√© int√©ressant de le faire moi-m√™me.\nJe vous pr√©sente donc Cercat aka Certificate Catcher.\nLe principe est simple, le service se connecte via websocket au stream de Certstream, compare le domaine certifi√© √† une regexp et si il y a correspondance, un message est post√© sur Slack :\net dans les logs :\n1 2 2020/04/14 17:29:40 [INFO] : A certificate for \u0026#39;www.XXXX.fr\u0026#39; has been issued : {\u0026#34;domain\u0026#34;:\u0026#34;www.XXXX.fr\u0026#34;,\u0026#34;SAN\u0026#34;:[\u0026#34;www.XXXX.fr\u0026#34;],\u0026#34;issuer\u0026#34;:\u0026#34;Let\u0026#39;s Encrypt\u0026#34;,\u0026#34;Addresses\u0026#34;:[\u0026#34;XX.XX.XX.183\u0026#34;,\u0026#34;XX.XX.XX.182\u0026#34;]} 2020/04/14 17:29:41 [INFO] : A certificate for \u0026#39;XXXX.fr\u0026#39; has been issued : {\u0026#34;domain\u0026#34;:\u0026#34;XXXX.fr\u0026#34;,\u0026#34;SAN\u0026#34;:[\u0026#34;mail.XXXX.fr\u0026#34;,\u0026#34;XXXX.fr\u0026#34;,\u0026#34;www.XXXX.fr\u0026#34;],\u0026#34;issuer\u0026#34;:\u0026#34;Let\u0026#39;s Encrypt\u0026#34;,\u0026#34;Addresses\u0026#34;:[\u0026#34;XX.XX.XX.108\u0026#34;]} La configuration est dans le README et des binaires pr√©-compil√©s sont fournis ICI parce que je suis gentil.\nEn faisant des tests sur les domaines en .fr je suis d\u0026rsquo;ailleurs tomb√© sur √ßa, un bel exemple de phishing :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \u0026#34;domain\u0026#34;:\u0026#34;google-france.fr\u0026#34;, \u0026#34;SAN\u0026#34;:[ \u0026#34;eset.fr.nf\u0026#34;, \u0026#34;google-france.fr\u0026#34;, \u0026#34;page-accueil.info\u0026#34;, \u0026#34;www.eset.fr.nf\u0026#34;, \u0026#34;www.google-france.fr\u0026#34;, \u0026#34;www.page-accueil.info\u0026#34; ], \u0026#34;issuer\u0026#34;:\u0026#34;Let\u0026#39;s Encrypt\u0026#34;, \u0026#34;Addresses\u0026#34;:[ \u0026#34;X.X.X.24\u0026#34; ] } En esp√©rant que √ßa serve √† d\u0026rsquo;autres.\nEnjoy\n","date":"2020-04-17T00:00:00Z","permalink":"https://thomas.labarussias.fr/posts/cercat/","title":"Cercat"},{"content":"Un petit post d\u0026rsquo;auto-promo (apr√®s des mois d\u0026rsquo;absences\u0026hellip;).\nJ\u0026rsquo;ai not√© r√©cemment que mon petit falcosidekick a d√©pass√© les 100000 pulls sur le DockerHub. Je suis bluff√©, surtout que je sais que des entit√©s grosses et connues l\u0026rsquo;utilisent (je ne sais pas si je peux dire qui, donc je me tais, sorry).\nUn petit graphe pour montrer l\u0026rsquo;historique (la l√©gende est illisible, mais les dates sont obtenables en survolant) :\nMerci √† tous ceux qui l\u0026rsquo;utilisent et bien s√ªr √† toute l\u0026rsquo;√©quipe derri√®re falco. J\u0026rsquo;ai d\u0026rsquo;autres id√©es en r√©serve pour am√©liorer, j\u0026rsquo;esp√®re avoir le temps de m\u0026rsquo;y atteler.\nEnjoy\n","date":"2020-02-18T00:00:00Z","image":"https://thomas.labarussias.fr/img/falcosidekick-color-feature.png","permalink":"https://thomas.labarussias.fr/posts/falcosidekick-100k-pulls/","title":"Falcosidekick 100k Pulls"},{"content":"Je viens de sortir la version 2.9.0 de falcosidekick et en outre un nouvel output, Opsgenie, j\u0026rsquo;ai √©galement refait l\u0026rsquo;avatar du projet. Il est d√©sormais en couleurs et a une forme globale carr√©e, pour faciliter l\u0026rsquo;utilisation en ic√¥ne (Slack, Teams, \u0026hellip;).\nVoil√† le r√©sultat :\nCe qui donne ceci dans Slack :\nEn ce qui concerne Opsgenie, voil√† le r√©sultat :\nLe repo Github et l\u0026rsquo;image sur le DockerHub.\nEnjoy\n","date":"2019-10-05T00:00:00Z","image":"https://thomas.labarussias.fr/img/falcosidekick-color-feature.png","permalink":"https://thomas.labarussias.fr/posts/falcosidekick-v-2-9-0-new-avatar/","title":"Falcosidekick 2.9.0 : nouvelle int√©gration et nouvel avatar"},{"content":"Je tra√Æne pas mal sur le slack de sysdig, o√π on parle bien entendu de falco. Un probl√®me tr√®s r√©current des utilisateurs est l\u0026rsquo;existence ou non de modules kernel pr√©compil√©s pour leurs versions de kernel.\nQuand le module n\u0026rsquo;est pas pr√©sent sur la machine h√¥te, l\u0026rsquo;installeur tente de le t√©l√©charger depuis un bucket S3, c\u0026rsquo;est pratique, mais √©tant donn√© l\u0026rsquo;immense vari√©t√© d\u0026rsquo;architectures et de versions de kernel dans la nature, impossible de tous les avoir tout pr√™ts au chaud sur S3. Jusqu\u0026rsquo;√† pr√©sent, la seule mani√®re pour savoir si la version du module pour son kernel est pr√©sente ou non sur le bucket est d\u0026rsquo;aller sur la page indigeste qui est celle-ci : https://s3.amazonaws.com/download.draios.com/stable/sysdig-probe-binaries/index.html\nPas tr√®s pratique (√ßa oblige √† faire du ctrl+F pour recherhcer) et surtout la page est de plus en plus volumineuse.\nJ\u0026rsquo;ai donc cod√© un petit machin qui parse cet index et ressort le tout sous forme de tableaux dans lequels on peut chercher et √©galement transmettre les diens vers les modules.\nLe domaine est temporaire jusqu\u0026rsquo;√† nouvel ordre : https://thomas.labarussias.fr/falco-probes/?falcoversion=0.17.0\nEn esp√©rant que √ßa serve √† quelqu\u0026rsquo;un d\u0026rsquo;autre que moi, en tout cas c\u0026rsquo;est tr√®s pratique pour v√©rifier si les soucis d\u0026rsquo;installation de falco d\u0026rsquo;une personne viennent de l\u0026rsquo;absence du module ou non.\nEnjoy\n","date":"2019-09-23T00:00:00Z","image":"https://thomas.labarussias.fr/img/falco-feature.png","permalink":"https://thomas.labarussias.fr/posts/falco-probes/","title":"Falco Probes"},{"content":"Je suis tomb√© chart.xkcd parmi les flux RSS que je suis. J\u0026rsquo;ai trouv√© l\u0026rsquo;id√©e amusante et le rendu agr√©able, j\u0026rsquo;en ai donc fait un micro shortcode pour Hugo :\n1 2 3 4 5 6 7 8 9 10 \u0026lt;div\u0026gt; \u0026lt;svg class=\u0026#39;{{ .Get \u0026#34;name\u0026#34; }}\u0026#39;\u0026gt;\u0026lt;/svg\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/chart.xkcd@1/dist/chart.xkcd.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; const svg{{ .Get \u0026#34;name\u0026#34; | safeJS }} = document.querySelector(\u0026#39;.{{ .Get \u0026#34;name\u0026#34; }}\u0026#39;); new chartXkcd.{{ .Get \u0026#34;type\u0026#34; | safeJS }}(svg{{ .Get \u0026#34;name\u0026#34; | safeJS }}, { {{ .Inner | safeJS }} }); \u0026lt;/script\u0026gt; \u0026lt;/div\u0026gt; A caler dans layout/shortcodes/chart-xkcd.html.\nTrois types de diagrammes sont dispos pour le moment : Line, Pie, Bar, XY, Radar.\nLes options de chaque diagramme sont trouvables dans la doc.\nExemples Line 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 {{\u0026lt; chart-xkcd name=\u0026#34;line\u0026#34; type=\u0026#34;Line\u0026#34; \u0026gt;}} title: \u0026#39;A vs B\u0026#39;, xLabel: \u0026#39;Abscisse\u0026#39;, yLabel: \u0026#39;Ordonnee\u0026#39;, data: { labels:[\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;6\u0026#39;,\u0026#39;7\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;9\u0026#39;, \u0026#39;10\u0026#39;], datasets: [{ label: \u0026#39;A\u0026#39;, data: [30, 2500, 200, 300, 250 ,800, 1500, 2900, 5000, 800], }, { label: \u0026#39;B\u0026#39;, data: [0, 1, 30, 70, 80, 100, 50, 80, 40, 150], }] }, options: { // optional yTickCount: 10, } {{\u0026lt; /chart-xkcd \u0026gt;}} Pie 1 2 3 4 5 6 7 8 9 10 11 12 13 {{\u0026lt; chart-xkcd name=\u0026#34;pie\u0026#34; type=\u0026#34;Pie\u0026#34; \u0026gt;}} title: \u0026#39;A B C D E\u0026#39;, data: { labels:[ \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;], datasets: [{ data: [200, 122, 60, 130, 44,], }] }, options: { innerRadius: 0.5, // mettre √† 0 pour obtenir un diagramme camembert (pie chart) legendPosition: chartXkcd.config.positionType.upRight, } {{\u0026lt; /chart-xkcd \u0026gt;}} Bar 1 2 3 4 5 6 7 8 9 10 11 12 {{\u0026lt; chart-xkcd name=\u0026#34;bar\u0026#34; type=\u0026#34;Bar\u0026#34; \u0026gt;}} title: \u0026#34;A B C D\u0026#34;, data: { labels:[\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;], datasets: [{ data: [20, 33, 5, 12], }] }, options: { // optional yTickCount: 8, } {{\u0026lt; /chart-xkcd \u0026gt;}} XY 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 {{\u0026lt; chart-xkcd name=\u0026#34;xy\u0026#34; type=\u0026#34;XY\u0026#34; \u0026gt;}} title: \u0026#39;A vs B\u0026#39;, xLabel: \u0026#39;Abscisse\u0026#39;, yLabel: \u0026#39;Ordonnee\u0026#39;, data: { datasets: [{ label: \u0026#39;A\u0026#39;, data: [{ x: 1, y: 30 }, { x: 3, y: 8 }, { x: 5, y: 45 }, { x: 7, y: 22 }, { x: 9, y: -4 }], }, { label: \u0026#39;B\u0026#39;, data: [{ x: -2, y: 12 }, { x: 4, y: -20 }, { x: 6, y: 53 }, { x: 8, y: 12 }, { x: 10, y: 20 }], }], }, options: { xTickCount: 10, yTickCount: 10, showLine: false, dotSize: 1, } {{\u0026lt; /chart-xkcd \u0026gt;}} Avec options: {showLine: true} :\nRadar 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 {{\u0026lt; chart-xkcd name=\u0026#34;radar\u0026#34; type=\u0026#34;Radar\u0026#34; \u0026gt;}} title: \u0026#39;A vs B\u0026#39;, data: { labels: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;], datasets: [{ label: \u0026#39;A\u0026#39;, data: [4, 1, 3, 3, 2], }, { label: \u0026#39;B\u0026#39;, data: [1, 4, 2, 3, 1], }], }, options: { showLegend: true, dotSize: .7, showLabels: true, }, {{\u0026lt; /chart-xkcd \u0026gt;}} ","date":"2019-09-12T00:00:00Z","image":"https://thomas.labarussias.fr/posts/chart-xkcd/img/chart-xkcd-feature_hu_95762f490f74b67f.png","permalink":"https://thomas.labarussias.fr/posts/chart-xkcd/","title":"Chart XKCD"},{"content":"Nouvelle release, la 2.8.0, de mon proxy pour falco.\nLa grosse feature √©tant l\u0026rsquo;ajout de NATS (une message queue en Go) comme sortie.\nLe repo Github et l\u0026rsquo;image sur le DockerHub.\nEnjoy\n","date":"2019-09-11T00:00:00Z","image":"https://thomas.labarussias.fr/img/falcosidekick-feature.png","permalink":"https://thomas.labarussias.fr/posts/falcosidekick-v-2-8-0/","title":"Falcosidekick 2.8.0"},{"content":"Afin de parfaire mes connaissances sur kubernetes, aka k8s pour les intimes, j\u0026rsquo;avais envie de monter un cluster sur mon laptop, pas juste un noeud tout seul. Jusqu\u0026rsquo;√† pr√©sent je n\u0026rsquo;avais test√© que des solutions pour avoir des k8s mono-noeud, c\u0026rsquo;est sympa, mais trop √©loign√© de la r√©alit√©, surtout si on veut tester des m√©thodes de r√©silience, d\u0026rsquo;auto-scaling de pods, de deployments, de daemonset, etc.\nEt l√†, la r√©v√©lation ! Je connaissais d√©j√† k3s, le k8s ultra all√©g√© de chez rancher et il s\u0026rsquo;av√®re qu\u0026rsquo;ils ont d√©velopp√© un petit utilitaire pour monter un cluster dans des containeurs docker avec, le bien nomm√© k3d.\nApr√®s plusieurs heures de tests, je suis emball√©, c\u0026rsquo;est ultra rapide, ultra light et √ßa fonctionne avec tous les outils classiques. Un ingress controller bas√© sur traefik est directement d√©ploy√©, donc on a de base un environnement fonctionnel. Simple. Efficace.\nInstallation de k3d Rien de compliqu√© pour l\u0026rsquo;installer, plusieurs m√©thodes sont fournies sur le repo Github officiel. Comme c\u0026rsquo;est du go, aucune d√©pendance. Easy.\nCr√©er son premier cluster 1 ~ $ k3d create -n mon-cluster-test --publish 80 --publish 8080 --publish 443 -w 2 1 2 3 4 5 6 7 8 9 10 11 12 13 2019/09/05 23:16:34 Created cluster network with ID cae80bddca7cf614494b9d97f7d6edf2b14d45864ef1aa0b1a899a93122ecc1b 2019/09/05 23:16:34 Created docker volume k3d-mon-cluster-test-images 2019/09/05 23:16:34 Creating cluster [mon-cluster-test] 2019/09/05 23:16:34 Creating server using docker.io/rancher/k3s:v0.7.0... 2019/09/05 23:16:34 Pulling image docker.io/rancher/k3s:v0.7.0... 2019/09/05 23:16:47 Booting 2 workers for cluster mon-cluster-test 2019/09/05 23:16:48 Created worker with ID b0c019c001376c9aa07f8fb65b52da1b2d52fbe61f25cb24c7198c5b122a2a09 2019/09/05 23:16:49 Created worker with ID a9d959899a2119606248bf8dd5d681f05efb7232d19c5f8206ffb5025f10885b 2019/09/05 23:16:49 SUCCESS: created cluster [mon-cluster-test] 2019/09/05 23:16:49 You can now use the cluster with: export KUBECONFIG=\u0026#34;$(k3d get-kubeconfig --name=\u0026#39;mon-cluster-test\u0026#39;)\u0026#34; kubectl cluster-info Sur ma machine, l\u0026rsquo;ex√©cution a pris environ 20s, en sachant que 95% du temps est li√© la r√©cup√©ration de l\u0026rsquo;image k3s. Impressionnant.\nUne petite explication des arguments :\n-n : le nom de notre cluster k8s --publish 80 --publish 8080 --publish 443 : les ports qu\u0026rsquo;on va exposer, comme c\u0026rsquo;est fait avec la commande docker run -w 2 : le nombre de workers qu\u0026rsquo;on veut On peut lister nos clusters :\n1 2 3 4 5 6 ~ $ k3d ls +------------------+------------------------------+---------+---------+ | NAME | IMAGE | STATUS | WORKERS | +------------------+------------------------------+---------+---------+ | mon-cluster-test | docker.io/rancher/k3s:v0.7.0 | running | 2/2 | +------------------+------------------------------+---------+---------+ L\u0026rsquo;image est effectivement de taille r√©duite (proportionnellement aux autres solutions) :\n1 2 REPOSITORY TAG IMAGE ID CREATED SIZE rancher/k3s v0.7.0 f1ec9d3fbf66 6 weeks ago 119MB Se connecter au cluster Comme pr√©cis√© dans les logs de cr√©ation, on peut r√©cup√©rer le kubeconfig associ√© pour utiliser les outils classiques (kubectl, k9s, helm, etc) :\n1 ~ $ export KUBECONFIG=\u0026#34;$(k3d get-kubeconfig --name=\u0026#39;mon-cluster-test\u0026#39;)\u0026#34; 1 2 3 4 5 ~ $ kubectl get nodes NAME STATUS ROLES AGE VERSION k3d-mon-cluster-test-server Ready master 2m v1.14.4-k3s.1 k3d-mon-cluster-test-worker-0 Ready worker 2m v1.14.4-k3s.1 k3d-mon-cluster-test-worker-1 Ready worker 2m v1.14.4-k3s.1 Premier d√©ploiement Afin de tester tout cela, nous allons appliquer un premier deployment et tenter d\u0026rsquo;y acc√©der. Cela sera un simple micro-service qui nous r√©pondra quelques infos sur lui-m√™me (sur quel noeud il tourne, son nom, le contenu de la requ√™te HTTP qu\u0026rsquo;il a re√ßue, etc). Le container qui sera utilis√© est fourni par ailleurs par ceux derri√®re traefik : containous/whoami.\nCr√©ation d\u0026rsquo;un namespace d√©di√© 1 ~ $ kubectl create namespace whoami C\u0026rsquo;est juste histoire de bien segmenter les choses.\nApplication du deployment 1 ~ $ kubectl create deployment whoami --image=containous/whoami -n whoami Scaling du replicaSet Nous avons un cluster √† 2 noeuds, √ßa serait dommage de n\u0026rsquo;avoir qu\u0026rsquo;un seul pod, augmentons √† 2 le replicaSet associ√© :\n1 ~ $ kubectl scale --replicas 2 deployment/whoami -n whoami 1 2 3 ~ $ kubectl get rs -n whoami NAME DESIRED CURRENT READY AGE whoami-756586b9ff 2 2 2 4m33s Cr√©ation du service Nous avons 2 pods, nous allons cr√©er un service pour avoir une r√©partition de charge :\n1 ~ $ kubectl create service clusterip whoami --tcp=80:80 -n whoami Cr√©ation de l\u0026rsquo;ingress Tout est pr√™t au sein de notre cluster, il est temps de nous permettre d\u0026rsquo;acc√©der √† notre micro-service, on va utiliser une ressource de type ingress :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ~ $ cat \u0026lt;\u0026lt;EOF | kubectl apply -n whoami -f - apiVersion: extensions/v1beta1 kind: Ingress metadata: name: whoami annotations: ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; spec: rules: - http: paths: - path: / backend: serviceName: whoami servicePort: 80 EOF Testons le micro-service A la cr√©ation du cluster, nous avons publier le port 80 au niveau de l\u0026rsquo;host, il est temps de trouver le port qui a √©t√© associ√© (bind) :\n1 ~ $ docker inspect --format=\u0026#39;{{range $p, $conf := .NetworkSettings.Ports}} {{$p}} -\u0026gt; {{(index $conf 0).HostPort}} {{end}}\u0026#39; $(docker ps --filter \u0026#34;name=k3d-mon-cluster-test-server\u0026#34; -q) 1 443/tcp -\u0026gt; 32810 6443/tcp -\u0026gt; 6443 80/tcp -\u0026gt; 32811 8080/tcp -\u0026gt; 32809 L\u0026rsquo;ingress √©coute sur le port 80, le port associ√© est donc le 32811 dans mon cas. Faisons plusieurs appels et v√©rifions :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ~ $ curl http://localhost:32811 Hostname: whoami-756586b9ff-4mqb6 IP: 127.0.0.1 IP: ::1 IP: 10.42.2.4 IP: fe80::a89f:5eff:fef5:d426 RemoteAddr: 10.42.1.3:36824 GET / HTTP/1.1 Host: localhost:32811 User-Agent: curl/7.47.0 Accept: */* Accept-Encoding: gzip X-Forwarded-For: 10.42.1.1 X-Forwarded-Host: localhost:32811 X-Forwarded-Port: 32811 X-Forwarded-Proto: http X-Forwarded-Server: traefik-56688c4464-wlk2r X-Real-Ip: 10.42.1.1 ~ $ curl http://localhost:32811 Hostname: whoami-756586b9ff-6wn52 IP: 127.0.0.1 IP: ::1 IP: 10.42.0.4 IP: fe80::7c0f:1fff:fe2b:bcb2 RemoteAddr: 10.42.1.3:41180 GET / HTTP/1.1 Host: localhost:32811 User-Agent: curl/7.47.0 Accept: */* Accept-Encoding: gzip X-Forwarded-For: 10.42.1.1 X-Forwarded-Host: localhost:32811 X-Forwarded-Port: 32811 X-Forwarded-Proto: http X-Forwarded-Server: traefik-56688c4464-wlk2r X-Real-Ip: 10.42.1.1 Nous avons bien 2 r√©ponses diff√©rentes :\n1 2 3 4 5 Hostname: whoami-756586b9ff-4mqb6 IP: 10.42.2.4 Hostname: whoami-756586b9ff-6wn52 IP: 10.42.0.4 Qui correspondent √† nos 2 pods :\n1 2 3 4 ~ $ kubectl get pods -n whoami NAME READY STATUS RESTARTS AGE whoami-756586b9ff-4mqb6 1/1 Running 0 24m whoami-756586b9ff-6wn52 1/1 Running 0 20m Enjoy\n","date":"2019-09-05T00:00:00Z","image":"https://thomas.labarussias.fr/img/kubernetes-feature.png","permalink":"https://thomas.labarussias.fr/posts/utiliser-k3d/","title":"Utiliser k3d pour avoir un cluster k8s en local"},{"content":"Les mainteneurs de falco m\u0026rsquo;ont propos√© de migrer falcosidekick au sein de l\u0026rsquo;organisation officielle falcosecurity. Il devient donc un projet officiel üéâüòç.\nLe repo Github et l\u0026rsquo;image sur le DockerHub.\nAu passage, j\u0026rsquo;ai sorti la 2.7.1 qui met √† jour la version de Go utilis√©e (1.12).\nEnjoy\n","date":"2019-08-28T00:00:00Z","image":"https://thomas.labarussias.fr/img/falcosidekick-color-feature.png","permalink":"https://thomas.labarussias.fr/posts/falcosidekick-migre-vers-falcosecurity/","title":"Falcosidekick fait d√©sormais partie de l'organisation Falcosecurity"},{"content":"Nouvelle release, la 2.7.0, de mon proxy pour falco.\nLa grosse feature √©tant l\u0026rsquo;ajout de Loki comme sortie :\nLe repo Github et l\u0026rsquo;image sur le DockerHub.\nEnjoy\n","date":"2019-08-27T00:00:00Z","image":"https://thomas.labarussias.fr/img/falcosidekick-feature.png","permalink":"https://thomas.labarussias.fr/posts/falcosidekick-v-2-7-0/","title":"Falcosidekick 2.7.0"},{"content":"Nouvelle release, la 2.6.0, de mon proxy pour falco.\nLa grosse feature √©tant l\u0026rsquo;ajout du SMTP (envoi d\u0026rsquo;email) comme sortie :\nAfin de respecter les standards, la version html contient √©galement la version plaintext. Il est aussi possible d\u0026rsquo;envoyer uniquement la version plaintext, utile pour certains syst√®mes de ticketing qui utilisent l\u0026rsquo;email pour la cr√©ation.\nLe repo Github et l\u0026rsquo;image sur le DockerHub.\nEnjoy\n","date":"2019-08-26T00:00:00Z","image":"https://thomas.labarussias.fr/img/falcosidekick-color-feature.png","permalink":"https://thomas.labarussias.fr/posts/falcosidekick-v-2-6-0/","title":"Falcosidekick 2.6.0"},{"content":"Traefik poss√®de une UI basique qui est par d√©faut expos√©e sur un port diff√©rent. Il est possible de faire en sorte que Traefik serve lui m√™me de proxy, cela permet :\nne plus avoir √† utiliser un port diff√©rent pour acc√©der l\u0026rsquo;UI, mais un domaine classique (\u0026quot;traefik.mondomaine.net\u0026quot; par ex.) forcer l\u0026rsquo;acc√®s en https avec en prime un certificat Let\u0026rsquo;s Encrypt automatique et gratuit permettre de rajouter une authentification, par d√©faut, l\u0026rsquo;UI est ouverte √† tout une fois activ√©e Dans mon cas, je fais tourner Traefik dans un container, mais √ßa marchera pareil si vous le fa√Ætes tourner directement sur l\u0026rsquo;host, prenez juste soin de filtrer le port de l\u0026rsquo;UI (8080 par d√©faut) pour qu\u0026rsquo;il n\u0026rsquo;accepte que les connexions de la boucle local (127.0.0.1).\nVoil√† ce qu\u0026rsquo;il faut avoir √† minima dans sa configuration config.toml :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 ################################################################ # Configuration globale ################################################################ defaultEntryPoints = [\u0026#34;http\u0026#34;, \u0026#34;https\u0026#34;] [entryPoints] [entryPoints.http] address = \u0026#34;:80\u0026#34; # traefik ecoute sur le port 80 [entryPoints.http.redirect] entryPoint = \u0026#34;https\u0026#34; # redirection http \u0026gt; https [entryPoints.https] address = \u0026#34;:443\u0026#34; # traefik ecoute sur le port 443 [entryPoints.https.tls] minVersion = \u0026#34;VersionTLS12\u0026#34; # version minimum de TLS acceptee [entryPoints.ui] address=\u0026#34;127.0.0.1:8080\u0026#34; # on ecoute uniquement sur la boucle locale pour ce port [entryPoints.ui.auth] [entryPoints.ui.auth.basic] users = [\u0026#34;XXXX:YYYY\u0026#34;] # les identifiants au format htpasswd ################################################################ # Configuration pour let\u0026#39;s encrypt ################################################################ [acme] email = \u0026#34;xxx@yyy.zzz\u0026#34; # votre mail pour lets encrypt storage = \u0026#34;/certs/acme.json\u0026#34; entryPoint = \u0026#34;https\u0026#34; onDemand = true # demande automatique de certificat acmeLogging = true [acme.httpChallenge] entryPoint = \u0026#34;http\u0026#34; ################################################################ # Configuration de l\u0026#39;API de Traefik ################################################################ [api] entryPoint = \u0026#34;ui\u0026#34; # l API ecoutera sur cet entrypoint dashboard = true [api.statistics] recentErrors = 50 ################################################################ # Configuration pour l\u0026#39;UI de Traefik ################################################################ [file] [frontends] [frontends.ui] backend = \u0026#34;ui\u0026#34; passHostHeader = true [frontends.ui.routes.default] rule = \u0026#34;Host:ui.mondomaine.net\u0026#34; # votre domaine a configurer [backends] [backends.ui] [backends.ui.servers.default] url = \u0026#34;http://127.0.0.1:8080\u0026#34; # le backend a utiliser qui s avere etre l entrypoint de l API Enjoy\n","date":"2019-08-26T00:00:00Z","image":"https://thomas.labarussias.fr/posts/traefik-proxyfier-dashboard/img/traefik-feature_hu_790506cc094ac6b8.png","permalink":"https://thomas.labarussias.fr/posts/traefik-proxyfier-dashboard/","title":"Proxifier Traefik par Traefik"},{"content":" int64 ü†Æ string FormatInt 1 strconv.FormatInt(i int64, base int) Itoa 1 2 strconv.Itoa(i int) // Itoa is equivalent to FormatInt(int64(i), 10). string ü†Æ int64 ParseInt 1 strconv.ParseInt(s string, base int, bitSize int) Atoi 1 2 strconv.Atoi(s string) // Atoi is equivalent to ParseInt(s, 10, 0), converted to type int. string ü†Æ Time Pour le layout. Pour la location. Parse 1 time.Parse(layout, value string) ParseInLocation 1 time.ParseInLocation(layout, value string, loc *Location) Time ü†Æ string Pour le layout.\nTime.Format 1 2 var t time.Time t.Format(layout string) ","date":"2019-08-21T00:00:00Z","permalink":"https://thomas.labarussias.fr/posts/golang-conversion-types/","title":"Conversion de Types en Go"},{"content":"Je tentais de d√©coder la partie payload d\u0026rsquo;un token JWT (https://scotch.io/tutorials/the-anatomy-of-a-json-web-token) quand j\u0026rsquo;ai eu l\u0026rsquo;erreur suivante :\n1 panic: illegal base64 data at input byte 349 Ma fa√ßon de faire √©tait pourtant classique et a toujours fonctionn√© auparavant :\n1 base64.StdEncoding.DecodeString(s) Et le d√©codage du string via un autre outil ne posait pas de souci. üòß\nLa solution se trouvait une fois de plus dans la documentation de Go : https://golang.org/pkg/encoding/base64/#pkg-variables\nIl existe plusieurs fonctions de d√©codage qui prennent ou non en compte les caract√®res de padding, en changeant pour :\n1 base64.RawStdEncoding.DecodeString(s) Mon payload √©tait d√©cod√©.\nüëç ","date":"2019-08-19T00:00:00Z","permalink":"https://thomas.labarussias.fr/posts/decoder-du-base64-en-go/","title":"D√©coder du base64 en Go"}]